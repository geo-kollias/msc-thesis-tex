Section: The Problem

In 'Fixing The Inlining ``Problem''' [cite], Cliff Click describes an issue
that has emerged the last few years in the JVM ecosystem:

``“The Problem” is simply this: new languages on the JVM (e.g. JRuby) and new
programming paradigms (e.g. Fork Join) have exposed a weakness in the current
crop of inlining heuristics.  Inlining is not happening in a crucial point in
hot code exposed by these languages, and the lack of inlining is hurting
performance in a major way.  AND the inlining isn’t happening because The
Problem is a hard one to solve; (i.e. it’s not the case that we’ll wave our
wands and do a quick fix & rebuild HotSpot and the problem will go away).   John
Rose, Doug Lea and I all agree that it’s a Major Problem facing JVMs with long
and far reaching implications.``

Let's see what The Problem is with a small example in a Java-like language. The
Problem is getting the right amount of context in hot inner loops – which also
contain a mega-morphic virtual call in the loop and not much else.  Here’s a
simple loop doing “bitblit”: mashing two rectangles of bits (an image) together
using some function chosen before the loop, in this case OR’ing two rectangles
together essentially merging the image.

  // The function in the inner loop
  long or_word( long a, long b ) { return a|b; }
  // The iterator function
  void blit( long[] dst, long[] src1, long[] src2 ) {
    for( int i=0; i<dst.len; i++ )        // simple loop
      dst[i] = or_word(src1[i],src2[i]);  //   around a simple loop body
  }
  
Inlining the function “or_word” is crucial to performance here.  Without
inlining the compiler doesn’t know what the loop body does (because function
calls can in general do anything), and with inlining it can understand the
entire function completely – and then see it’s a simple loop around a stream of
array references.  At this point the JIT can do range-check elimination, loop
unrolling, and prefetching among other optimizations.

The Problem is that there are multiple variations on “or_word” \emph{and}
the wrapping iterator gets complex.  It’s the product of these two parts getting
complicated that makes The Problem.

Suppose the wrapping blit iterator gets complex – it’s walking all the bits in a
canvas of partially obscured rectangular images, and each image is a collection
of 24 bits worth of pixels and is possibly boxed or bounded by some other
rectangles:
  // A sample complex iterator function
  void blit( Rectangle bounding_box, Image dst, Image src1, Image src2 ) {
    for( int i=bounding_box.low; i<bounding_box.high; i++ )
      for( int j=bounding_box.left; j<bounding_box.right; j++ ) {
        idx = i*bounding_box.width+j;
        if( dst.is_rgb_pixels ) {
          dst.red  [idx] = or_word(src1.red  [idx],src2.red  [idx]);
          dst.blue [idx] = or_word(src1.blue [idx],src2.blue [idx]);
          dst.green[idx] = or_word(src1.green[idx],src2.green[idx]);
        } else if( dst.is_another_kind_of_pixels ) {
         ....other stuff....
        }
      }
    }
  }
  
Now on top of the complex iterator we want to do something other than “or_word“.
  We might also want to “and_word” (good for masking out images), “xor_word”
(merging images), “scale_word“,  “filter” and so on.  What we really want is a
way to pass in the function to apply on the basic data bits in the innermost
loop of our complicated iterator.  In Java we often do this with either a
Callable or a Runnable:
  // A sample complex iterator function
  void blit( CallableTwoArg fcn2arg, Rectangle bounding_box, Image dst, Image
src1, Image src2 ) {
    ...
      dst[idx] = fcn2arg.call(src1[idx],src2[idx]);
    ...
  }
  
We need only 1 copy of our large complicated iterator, and we can do all kinds
of things with Images.  Alas, that inner loop now contains a function call that
needs inlining and there are dozens of different functions for “fcn2arg.call”. 
The JIT does not know which one to inline here – because all dozen different
functions are called at various times.  Typically then the JIT does not inline
any of them, and instead opts for a virtual call.  Alas, while the virtual call
itself isn’t too bad the lack of knowledge of what goes on inside the virtual
call prevents all kinds of crucial optimizations: loop unrolling, range-check
elimination, all kinds of prefetching and alias analyses.

One solution  would be to make the inner function call a static (final) call -
then the JIT can inline. Of course, if we do that we need an iterator for the
“or_word” version, and one for the “and_word” version and one for the “xor_word”
version and so we need a lot of them. Also, we will need a new one for each
new function we can think of; we can't just name them all up front.  So we’ll
end up with a ton of these iterators each with a custom call in the inner loop.
All these iterators will start blowing out the instruction cache on our CPU,
costing us ~10x by itself, and besides it'a pain to maintain dozens of cloned
complex iterators.

Several Java ecosystem's prominent figures, like Cliff Click, John Rose, Doug
Lea, have proposed several solution that range from pure obscure technical
solutions to pure educational solutions, demonstrating possible ``megamorphic
inlining friendly'' coding styles.

Scala, as most of the modern JVM languages, is no exception and it suffers from
The Problem too and, actually, it affects its adoption negatively. At the end of
2011 an email from a Yammer's employer towards the TypeSafe's CEO, about Scala
shortcomings, leaked to the public {cite
http://www.infoq.com/news/2011/11/yammer-scala}. Most complaints were related
with The Problem and, more specifically, with the Scala standard
library collections' performance. We will see in the next chapter where exactly
the problem lies and how the Scala macros can help us alleviate it.


Section: Scala Def Macros

Since our implementation uses functionality from the newly introduced Scala
macros {cite Scala Macros, a Technical Report} let's firstly see the motivation
for adding them in a programming language and then a simple real example.


Subsection: Motivation

Compile-time metaprogramming has been recognized as a valuable tool for enabling
such programming techniques as:

- Language virtualization (overloading/overriding semantics of the original
programming language to enable deep embedding of DSLs),
- Program reification (providing programs with means to inspect their own code),
- Self-optimization (self-application of domain-specific optimizations based on
program reification),
- Algorithmic program construction (generation of code that is tedious to write
with the abstractions supported by a programming language).

A macro system for Scala allows programmers to write macro defs: functions that
are transparently loaded by the compiler and executed during compilation. This
realizes the notion of compile-time metaprogramming for Scala.

Our project falls in the third category where we use the macros to optimize the
Scala collections.


Subsection: Example

Here is a prototypical macro definition:

def m(x: T): R = macro implRef

At first glance macro definitions are equivalent to normal function definitions,
except for their body, which starts with the conditional keyword macro and is
followed by a possibly qualified identifier that refers to a static macro
implementation method.

If, during type-checking, the compiler encounters an application of the macro
m(args), it will expand that application by invoking the corresponding macro
implementation method, with the abstract-syntax trees (ASTs) of the argument
expressions args as arguments. The result of the macro implementation is another
AST, which will be inlined at the call site and will be type-checked in turn.

The following code snippet declares a macro definition assert that references a
macro implementation Asserts.assertImpl (definition of assertImpl is provided
below):

def assert(cond: Boolean, msg: Any) = macro Asserts.assertImpl

A call assert(x < 10, "limit exceeded") would then lead at compile time to an
invocation

assertImpl(c)(<[ x < 10 ]>, <[ “limit exceeded” ]>)

where c is a context argument that contains information collected by the
compiler at the call site, and the other two arguments are ASTs representing the
two expressions x < 10 and limit exceeded.

<[ expr ]> denotes the AST that represents the expression expr. In reality, the
syntax trees would be constructed from the types in trait
scala.reflect.api.Trees and the two expressions above would look like this:

Literal(Constant("limit exceeded"))
Apply(
  Select(Ident(newTermName("x")), newTermName("\$less"),
  List(Literal(Constant(10)))))
  
Here is a possible implementation of the assert macro:

import scala.reflect.macros.Context
import scala.language.experimental.macros
object Asserts {
  def raise(msg: Any) = throw new AssertionError(msg)
  def assertImpl(c: Context)
    (cond: c.Expr[Boolean], msg: c.Expr[Any]) : c.Expr[Unit] =
   if (assertionsEnabled)
      c . Expr(If(Select(cond.tree, newTermName("unary_\$bang")),
Apply(Ident(newTermName("raise")), List(msg.tree)), Literal(Constant(()))))
}

As the example shows, a macro implementation takes several parameter lists.
First comes a single parameter, of type scala.reflect.macros.Context. This is
followed by a list of parameters that have the same names as the macro
definition parameters. But where the original macro parameter has type T, a
macro implementation parameter has type c.Expr[T]. Expr[T] is a type defined in
Context that wraps an AST of type T. The result type of the
assertImpl macro implementation is again a wrapped tree, of type c.Expr[Unit].


Subsection: Hygiene

Obviously the AST construction in the last example of the
previous section is cumbersome and error-prone. But it is also wrong. The tree
produced from a macro will be inlined and type-checked at the macro call site.
But that means that the identifier raise will be type-checked at a point where
it is most likely not visible, or in the worst case they might refer to
something else. In the macro literature, this insensitivity to bindings is
called non-hygienic {cite [19, 8]}.

However, it turns out that macros themselves can be used to solve both these
problems. A corner-stone of the technique is a macro called reify that produces
its tree one stage later.


Subsection: Reification and Splicing

The reify macro plays a crucial role in the proposed macro system. Its
definition as a member of Context is:

def reify [ T ] ( expr : T) : Expr [ T ] = macro . . .

Reify accepts a single parameter expr, which can be any well-typed Scala
expression, and creates a tree that, when compiled and evaluated, will recreate
the original tree expr. So reify is like time-travel: trees get re-constituted
at a later stage. If reify is called from normal compiled code, its effect is
that the AST passed to it will be recreated at run time.
Consequently, if reify is called from a macro implementation, its effect is that
the AST passed to it will be recreated at macro-expansion time
(which corresponds to run time for macros). This gives a convenient way to
create syntax trees from Scala code: pass the Scala code to reify, and the
result will be a syntax tree that represents that very same code.

Moreover, reify packages the result expression tree with the types and values of
all free references that occur in it. This means in effect that all
free references in the result are already resolved, so that re-typechecking the
tree is insensitive to its environment. All identifiers referred to from
an expression passed to reify are bound at the definition site, and not re-bound
at the call site. As a consequence, macros that generate trees only by the means
of passing expressions to reify are hygienic.

So in that sense, Scala macros are self-cleaning. Their basic form is minimal
and unhygienic, but that simple form is expressive enough to formulate a
reify macro, which can be used in turn to make tree construction in
macros concise and hygienic.

object Asserts {
  def assertionsEnabled = . . .
  def raise(msg: Any) = throw new AssertionError(msg)
  def assertImpl(c : Context)
    (cond: c.Expr[Boolean], msg: c.Expr[Any])
    : c.Expr[Unit] = 
    
    if(assertionsEnabled)
      c.reify(if(!cond.splice) raise(msg.splice) )
    else
      c.reify(())
}

Here, we see that we can use the Expr's splice method inside the reify in order
to inject other trees (Expr).

Reification and splicing are crucial to our implementation which will see in
the next chapter.