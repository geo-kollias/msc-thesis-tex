Section: The Problem

In 'Fixing The Inlining ``Problem''' [cite], Cliff Click describes an issue
that has emerged the last few years in the JVM ecosystem:

``The Problem is simply this: new languages on the JVM (e.g. JRuby) and new
programming paradigms (e.g. Fork Join) have exposed a weakness in the current
crop of inlining heuristics.  Inlining is not happening in a crucial point in
hot code exposed by these languages, and the lack of inlining is hurting
performance in a major way.  AND the inlining isn’t happening because The
Problem is a hard one to solve; (i.e. it’s not the case that we’ll wave our
wands and do a quick fix & rebuild HotSpot and the problem will go away).   John
Rose, Doug Lea and I all agree that it's a Major Problem facing JVMs with long
and far reaching implications.''

Let's see what The Problem is with a small example in a Java-like language. The
Problem is getting the right amount of context in hot inner loops – which also
contain a mega-morphic virtual call in the loop and not much else.  Here’s a
simple loop doing “bitblit”: mashing two rectangles of bits (an image) together
using some function chosen before the loop, in this case OR’ing two rectangles
together essentially merging the image.

  // The function in the inner loop
  long or_word( long a, long b ) { return a|b; }
  // The iterator function
  void blit( long[] dst, long[] src1, long[] src2 ) {
    for( int i=0; i<dst.len; i++ )        // simple loop
      dst[i] = or_word(src1[i],src2[i]);  //   around a simple loop body
  }
  
Inlining the function “or_word” is crucial to performance here.  Without
inlining the compiler doesn’t know what the loop body does (because function
calls can in general do anything), and with inlining it can understand the
entire function completely – and then see it’s a simple loop around a stream of
array references.  At this point the JIT can do range-check elimination, loop
unrolling, and prefetching, among other optimizations.

The Problem is that there are multiple variations on “or_word” \emph{and}
the wrapping iterator gets complex.  It’s the product of these two parts getting
complicated that makes The Problem.

Suppose the wrapping blit iterator gets complex - it’s walking all the bits in a
canvas of partially obscured rectangular images, and each image is a collection
of 24 bits worth of pixels and is possibly boxed or bounded by some other
rectangles:
  // A sample complex iterator function
  void blit( Rectangle bounding_box, Image dst, Image src1, Image src2 ) {
    for( int i=bounding_box.low; i<bounding_box.high; i++ )
      for( int j=bounding_box.left; j<bounding_box.right; j++ ) {
        idx = i*bounding_box.width+j;
        if( dst.is_rgb_pixels ) {
          dst.red  [idx] = or_word(src1.red  [idx],src2.red  [idx]);
          dst.blue [idx] = or_word(src1.blue [idx],src2.blue [idx]);
          dst.green[idx] = or_word(src1.green[idx],src2.green[idx]);
        } else if( dst.is_another_kind_of_pixels ) {
         ....other stuff....
        }
      }
    }
  }
  
Now on top of the complex iterator we want to do something other than
``or_word''.
  We might also want to “and_word” (good for masking out images), “xor_word”
(merging images), “scale_word“,  “filter” and so on.  What we really want is a
way to pass in the function to apply on the basic data bits in the innermost
loop of our complicated iterator.  In Java we often do this with either a
Callable or a Runnable:
  // A sample complex iterator function
  void blit( CallableTwoArg fcn2arg, Rectangle bounding_box, Image dst, Image
src1, Image src2 ) {
    ...
      dst[idx] = fcn2arg.call(src1[idx],src2[idx]);
    ...
  }
  
We need only 1 copy of our large complicated iterator, and we can do all kinds
of things with Images.  Alas, that inner loop now contains a function call that
needs inlining and there are dozens of different functions for “fcn2arg.call”. 
The JIT does not know which one to inline here – because all dozen different
functions are called at various times.  Typically then the JIT does not inline
any of them, and instead opts for a virtual call.  While the virtual call
itself isn’t too bad the lack of knowledge of what goes on inside the virtual
call prevents all kinds of crucial optimizations: loop unrolling, range-check
elimination, all kinds of prefetching and alias analyses.

One solution  would be to make the inner function call a static (final) call -
then the JIT can inline. Of course, if we do that we need an iterator for the
“or_word” version, one for the “and_word” version, and one for the “xor_word”
version, so we need a lot of them. Also, we will need a new one for each
new function we can think of; we cannot just name them all up front.  So we will
end up with a lot of these iterators each with a custom call in the inner loop.
All these iterators will start blowing out the instruction cache on our CPU, and
besides it's a pain to maintain dozens of cloned complex iterators.

Several Java ecosystem's prominent figures, like Cliff Click, John Rose, Doug
Lea, have proposed solutions that range from pure obscure technical to pure
educational ones, demonstrating possible ``megamorphic inlining friendly''
coding styles.

Scala, as most of the modern JVM languages, is no exception and it suffers from
The Problem too and, actually, it affects its adoption negatively. At the end of
2011, an email from a Yammer employee towards TypeSafe's CEO, about Scala
shortcomings, leaked to the public {cite
http://www.infoq.com/news/2011/11/yammer-scala}. Most complaints were related
with The Problem and, more specifically, with the Scala standard
library collections' performance. In the next chapter we will see where exactly
the problem lies and how Scala macros can help us alleviate it. Before that, it
would be helpful to overview the Scala collections and Scala macros.


Section: Scala Collections Overview

The Scala library systematically distinguishes between mutable and immutable
collections. A mutable collection can be updated or extended in place. This
means one can change, add, or remove elements of a collection as a side effect.
Immutable collections, by contrast, never change. We still have operations
that simulate additions, removals, or updates, but these operations will in each
case return a new collection and leave the old collection unchanged. We will see
in the next chapter how this mutable-immutable separation affects our macro
transformation plan.

All collection classes are found in the package scala.collection or one of its
sub-packages mutable, immutable, and generic. Most collection classes needed by
client code exist in three variants, which are located in packages
scala.collection, scala.collection.immutable, and scala.collection.mutable,
respectively. Each variant has different characteristics with respect to
mutability.

A collection in package scala.collection.immutable is guaranteed to be immutable
for everyone. Such a collection will never change after it is created.
Therefore, one can rely on the fact that accessing the same collection value
repeatedly at different points in time will always yield a collection with the
same elements.

A collection in package scala.collection.mutable is known to have some
operations that change the collection in place. So dealing with mutable
collections means one needs to understand which code changes which collection
when.

A collection in package scala.collection can be either mutable or immutable. For
instance, collection.IndexedSeq[T] is a superclass of both
collection.immutable.IndexedSeq[T] and collection.mutable.IndexedSeq[T]
Generally, the root collections in package scala.collection define the same
interface as the immutable collections, and the mutable collections in package
scala.collection.mutable typically add some side-effecting modification
operations to this immutable interface.

The difference between root collections and immutable collections is that
clients of an immutable collection have a guarantee that nobody can mutate the
collection, whereas clients of a root collection only promise not to change the
collection themselves. Even though the static type of such a collection provides
no operations for modifying the collection, it might still be possible that the
run-time type is a mutable collection which can be changed by other clients.

By default, Scala always picks immutable collections. For instance, if we just
write Set without any prefix or without having imported Set from somewhere, we
get an immutable set, and if we write Iterable we get an immutable iterable
collection, because these are the default bindings imported from the scala
package. To get the mutable default versions, we need to write explicitly
collection.mutable.Set, or collection.mutable.Iterable.

The following figure shows all collections in package scala.collection. These
are all high-level abstract classes or traits, which generally have mutable as
well as immutable implementations. (figure from ...)

[figure]

The following figure shows all collections in package
scala.collection.immutable. (figure from ...)

[figure]

And the following figure shows all collections in package
scala.collection.mutable. (figure from ...)

[figure]

This work focuses mainly on Seq's subtree, since it's where we can get the
most prominent speedups by exploiting the sequences' properties. A sequence is a
kind of iterable that has a length method and whose elements have fixed index
positions, starting from 0.


Section: Scala Def Macros

Since our implementation uses functionality from the newly introduced Scala
macros {cite Scala Macros, a Technical Report} let's firstly see the motivation
for adding macros in a programming language and then a simple real example.


Subsection: Motivation

Compile-time metaprogramming has been recognized as a valuable tool for enabling
such programming techniques as:

- Language virtualization (overloading/overriding semantics of the original
programming language to enable deep embedding of DSLs),
- Program reification (providing programs with means to inspect their own code),
- Self-optimization (self-application of domain-specific optimizations based on
program reification),
- Algorithmic program construction (generation of code that is tedious to write
with the abstractions supported by a programming language).

A macro system for Scala allows programmers to write macro defs: functions that
are transparently loaded by the compiler and executed during compilation. This
realizes the notion of compile-time metaprogramming for Scala.

Our project falls in the third category, since we use macros to optimize
the Scala collections.


Subsection: Example

Here is a prototypical macro definition:

def m(x: T): R = macro implRef

At first glance macro definitions are equivalent to normal function definitions,
except for their body, which starts with the conditional keyword macro and is
followed by a possibly qualified identifier that refers to a static macro
implementation method.

If, during type-checking, the compiler encounters an application of the macro
m(args), it will expand that application by invoking the corresponding macro
implementation method, with the abstract-syntax trees (ASTs) of the argument
expressions, args, as arguments. The result of the macro implementation is
another AST, which will be inlined at the call site and will be type-checked in
turn.

The following code snippet declares a macro definition, assert, that references
a macro implementation Asserts.assertImpl (the definition of assertImpl is
provided below):

def assert(cond: Boolean, msg: Any) = macro Asserts.assertImpl

A call assert(x < 10, "limit exceeded") would then lead at compile time to an
invocation

assertImpl(c)(<[ x < 10 ]>, <[ “limit exceeded” ]>)

where c is a context argument that contains information collected by the
compiler at the call site, and the other two arguments are ASTs representing the
two expressions x < 10 and limit exceeded.

<[ expr ]> denotes the AST that represents the expression expr. In reality, the
syntax trees would be constructed from the types in trait
scala.reflect.api.Trees and the two expressions above would look like this:

Literal(Constant("limit exceeded"))
Apply(
  Select(Ident(newTermName("x")), newTermName("\$less"),
  List(Literal(Constant(10)))))
  
Here is a possible implementation of the assert macro:

import scala.reflect.macros.Context
import scala.language.experimental.macros
object Asserts {
  def raise(msg: Any) = throw new AssertionError(msg)
  def assertImpl(c: Context)
    (cond: c.Expr[Boolean], msg: c.Expr[Any]) : c.Expr[Unit] =
   if (assertionsEnabled)
      c . Expr(If(Select(cond.tree, newTermName("unary_\$bang")),
Apply(Ident(newTermName("raise")), List(msg.tree)), Literal(Constant(()))))
}

As the example shows, a macro implementation takes several parameter lists,
i.e., it's a curried method. First comes a single parameter, of type
scala.reflect.macros.Context. This is followed by a list of parameters that have
the same names as the macro definition parameters. But where the original macro
parameter has type T, a macro implementation parameter has type c.Expr[T], which
is a path-dependent type and will be explained in the next chapter. Expr[T] is a
type defined in Context that wraps an AST of type T. The result type of the
assertImpl macro implementation is again a wrapped tree, of type c.Expr[Unit].


Subsection: Hygiene

Obviously the AST construction in the last example of the
previous section is cumbersome and error-prone. But it is also wrong. The tree
produced from a macro will be inlined and type-checked at the macro call site.
But this means that the identifier raise will be type-checked at a point where
it is most likely not visible, or in the worst case they might refer to
something else. In the macro literature, this insensitivity to bindings is
called non-hygienic {cite [19, 8]}.

However, it turns out that macros themselves can be used to solve both these
problems. A corner-stone of the technique is a macro called reify that produces
its tree one stage later.


Subsection: Reification and Splicing

The reify macro plays a crucial role in the proposed macro system. Its
definition as a member of Context is:

def reify [ T ] ( expr : T) : Expr [ T ] = macro . . .

Reify accepts a single parameter expr, which can be any well-typed Scala
expression, and creates a tree that, when compiled and evaluated, will recreate
the original tree expr. So reify is like time-travel: trees get re-constituted
at a later stage. If reify is called from normal compiled code, its effect is
that the AST passed to it will be recreated at run time.
Consequently, if reify is called from a macro implementation, its effect is that
the AST passed to it will be recreated at macro-expansion time
(which corresponds to run time for macros). This gives a convenient way to
create syntax trees from Scala code: pass the Scala code to reify, and the
result will be a syntax tree that represents that very same code.

Specifically, reify packages the result expression tree with the types and
values of all free references that occur in it. This means in effect that all
free references in the result are already resolved, so that re-typechecking the
tree is insensitive to its environment. All identifiers referred to from
an expression passed to reify are bound at the definition site, and not re-bound
at the call site. As a consequence, macros that generate trees only by means
of passing expressions to reify are hygienic.

So, in a sense, Scala macros are self-cleaning. Their basic form is minimal
and unhygienic, but that simple form is expressive enough to formulate a
reify macro, which in turn can be used to make tree construction in macros
concise and hygienic.

object Asserts {
  def assertionsEnabled = . . .
  def raise(msg: Any) = throw new AssertionError(msg)
  def assertImpl(c : Context)
    (cond: c.Expr[Boolean], msg: c.Expr[Any])
    : c.Expr[Unit] = 
    
    if(assertionsEnabled)
      c.reify(if(!cond.splice) raise(msg.splice) )
    else
      c.reify(())
}

Here, we see that we can use the Expr's splice method inside the reify
expression in order to inject other trees.

Reification and splicing are crucial to our implementation, which we will see in
the next chapter.