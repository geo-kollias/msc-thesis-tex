section: The Problem

In 'Fixing The Inlining ``Problem''' [cite], Cliff Click describes an issue
that has emerged the last years in the JVM ecosystem:

“The Problem” is simply this: new languages on the JVM (e.g. JRuby) and new
programming paradigms (e.g. Fork Join) have exposed a weakness in the current
crop of inlining heuristics.  Inlining is not happening in a crucial point in
hot code exposed by these languages, and the lack of inlining is hurting
performance in a major way.  AND the inlining isn’t happening because The
Problem is a hard one to solve; (i.e. it’s not the case that we’ll wave our
wands and do a quick fix & rebuild HotSpot and the problem will go away).   John
Rose, Doug Lea and I all agree that it’s a Major Problem facing JVMs with long
and far reaching implications.

Let's see what The Problem is with a small example in a Java-like language. The
Problem is getting the right amount of context in hot inner loops – which also
contain a mega-morphic virtual call in the loop and not much else.  Here’s a
simple loop doing “bitblit”: mashing two rectangles of bits (an image) together
using some function chosen before the loop, in this case OR’ing two rectangles
together essentially merging the image.

  // The function in the inner loop
  long or_word( long a, long b ) { return a|b; }
  // The iterator function
  void blit( long[] dst, long[] src1, long[] src2 ) {
    for( int i=0; i<dst.len; i++ )        // simple loop
      dst[i] = or_word(src1[i],src2[i]);  //   around a simple loop body
  }
  
Inlining the function “or_word” is crucial to performance here.  Without
inlining the compiler doesn’t know what the loop body does (because function
calls can in general do anything), and with inlining it can understand the
entire function completely – and then see it’s a simple loop around a stream of
array references.  At this point the JIT can do range-check elimination, loop
unrolling, and prefetching – leading to an easy 10x speedup over the not-inlined
loop.

The Problem is, is that there are multiple variations on “or_word” \emph{and}
the wrapping iterator gets complex.  It’s the product of these two parts getting
complicated that makes The Problem.

Suppose the wrapping blit iterator gets complex – it’s walking all the bits in a
canvas of partially obscured rectangular images, and each image is a collection
of 24 bits worth of pixels and is possibly boxed or bounded by some other
rectangles:
  // A sample complex iterator function
  void blit( Rectangle bounding_box, Image dst, Image src1, Image src2 ) {
    for( int i=bounding_box.low; i<bounding_box.high; i++ )
      for( int j=bounding_box.left; j<bounding_box.right; j++ ) {
        idx = i*bounding_box.width+j;
        if( dst.is_rgb_pixels ) {
          dst.red  [idx] = or_word(src1.red  [idx],src2.red  [idx]);
          dst.blue [idx] = or_word(src1.blue [idx],src2.blue [idx]);
          dst.green[idx] = or_word(src1.green[idx],src2.green[idx]);
        } else if( dst.is_another_kind_of_pixels ) {
         ....other stuff....
        }
      }
    }
  }
  
Now on top of the complex iterator we want to do something other than “or_word“.
  We might also want to “and_word” (good for masking out images), “xor_word”
(merging images), “scale_word“,  “filter” and so on.  What we really want is a
way to pass in the function to apply on the basic data bits in the innermost
loop of our complicated iterator.  In Java we often do this with either a
Callable or a Runnable:
  // A sample complex iterator function
  void blit( CallableTwoArg fcn2arg, Rectangle bounding_box, Image dst, Image
src1, Image src2 ) {
    ...
      dst[idx] = fcn2arg.call(src1[idx],src2[idx]);
    ...
  }
  
We need only 1 copy of our large complicated iterator, and we can do all kinds
of things with Images.  Alas, that inner loop now contains a function call that
needs inlining and there are dozens of different functions for “fcn2arg.call”. 
The JIT does not know which one to inline here – because all dozen different
functions are called at various times.  Typically then the JIT does not inline
any of them, and instead opts for a virtual call.  Alas, while the virtual call
itself isn’t too bad the lack of knowledge of what goes on inside the virtual
call prevents all kinds of crucial optimizations: loop unrolling, range-check
elimination, all kinds of prefetching and alias analyses.  In short, we lose our
10x speedup.

One solution  would be to make the inner function call a static (final) call -
then the JIT can inline. Of course, if we do that we need an iterator for the
“or_word” version, and one for the “and_word” version and one for the “xor_word”
version and so we need a lot of them. Also, we will need a new one for each
new function we can think of; we can't just name them all up front.  So we’ll
end up with a ton of these iterators each with a custom call in the inner loop.
All these iterators will start blowing out the instruction cache on our CPU,
costing us ~10x by itself, and besides it'a pain to maintain dozens of cloned
complex iterators.

Several Java ecosystem's prominent figures, like Cliff Click, John Rose, Doug
Lea, have proposed several solution that range from pure obscure technical
solutions to pure educational solutions, demonstrating possible ``megamorphic
inlining friendly'' coding styles.

Scala, as most of the modern JVM languages, is no exception and it suffers from
The Problem too. The problem is more obvious in Scala's standard library
collections. We will see in the next chapter where exactly the problem lies
and how the Scala macros can help us alleviate it.


Section: macros
