This chapter will introduce our work and the problem it tries to attack. It is a
real-world hard problem that affects the whole Java Virtual Machine (JVM) \fxfatal{add abbr}
ecosystem. This work tries to mitigate many of its implications. In the next chapter, we
will have an overview of the Scala language, its standard library collections and its new
compile-time reflection subsystem in order to prepare us for Chapter X
where we will explain our project's implementation and core functionality.
Chapter X provides us with several benchmarks, showing promising performance
speedups. Chapter X presents some similar work in the area. Finally, Chapter X
summarizes this work.

Section: The Problem and Our Approach

In ``Fixing The Inlining Problem'' \fxfatal{cite}, Cliff Click describes an issue
that has emerged the last few years in the JVM ecosystem:

``\emph{The Problem} is simply this: new languages on the JVM (e.g., JRuby) and new
programming paradigms (e.g., Fork Join) have exposed a weakness in the current
crop of inlining heuristics.  Inlining is not happening in a crucial point in
hot code exposed by these languages, and the lack of inlining is hurting
performance in a major way.  AND the inlining isn't happening because The
Problem is a hard one to solve; (i.e. it's not the case that we'll wave our
wands and do a quick fix \& rebuild HotSpot and the problem will go away).  
John Rose, Doug Lea and I all agree that it's a Major Problem facing JVMs with long
and far reaching implications.''

Let's see what \emph{The Problem} is with a small example in a Java-like language. The
Problem is getting the right amount of context in hot inner loops - which also
contain a mega-morphic virtual call in the loop and not much else.  Here is a
naive implementation of a \texttt{map} method that applies a predetermined
function to all the elements of a source array and assigns the result to a
destination array. In this case we increment all source's elements by one:

\begin{javaCode}
// The function in the inner loop
long add1(long a) {return a + 1;}
// The iterator function
void map(long[] dst, long[] src) {
  for(int i=0; i < dst.len; i++) // simple loop
    dst[i] = add1(src[i]); // around a simple loop body
}
\end{javaCode}

Inlining the function \texttt{add1} is crucial to performance here.  Without
inlining the compiler does not know what the loop body does (because function
calls can in general do anything), and with inlining it can understand the
entire function completely - and then see it's a simple loop around a stream of
array references.  At this point the JIT can do range-check elimination, loop
unrolling, and prefetching, among other optimizations.

The Problem is that there are multiple variations of \texttt{add1} \emph{and}
the wrapping iterator gets complex.  It's the product of these two parts getting
complicated that makes The Problem. In this work, we are mostly interested in
the first part, since the Scala collections iterators are not very big or
complex.

More often than not, after implementing \texttt{map}, we would like to add more
functions similar to \texttt{add1}. We might also want to add \texttt{add2}, \texttt{mult3},
\texttt{filter} and so on. What we really want is a way to pass in the function to
apply on the basic data bits in the innermost loop of our iterator.

In Java we often do this with either a \texttt{Callable} or a \texttt{Runnable}:\\

\begin{javaCode}
// A sample iterator function
void map( CallableOneArg fcn1arg, long[] dst, long[] src) {
  for(int i=0; i < dst.len; i++)
    dst[i] = fcn1arg.call(src[i]);
}
\end{javaCode}
  
We need only 1 copy of our iterator, and we can apply nearly all kinds of one
argument functions. Alas, that inner loop now contains a function call that
needs inlining and there are dozens of different functions for \sv{fcn1arg.call}.
The JIT does not know which one to inline here, because all these different
functions are called at different times.  Typically then the JIT does not inline
any of them, and instead opts for a virtual call.  While the virtual call
itself is not too bad, the lack of knowledge of what goes on inside the virtual
call prevents all kinds of crucial optimizations: loop unrolling, range-check
elimination, all kinds of prefetching and alias analyses.

One solution  would be to make the inner function call a static (final)
call, which then the JIT can inline. Of course, if we do that we need an
iterator for the \texttt{add1} version, one for the \texttt{add2} version, and one for the
\texttt{mult3} version, so we need a lot of them. Also, we will need a new one for
each new function we can think of; we cannot just name them all up front.  So we
will end up with a lot of these iterators each with a custom call in the inner
loop. All these iterators will start blowing out the instruction cache on our
CPU, and besides it is a pain to maintain dozens of cloned possibly complex
iterators.

Several of the Java ecosystem's prominent figures, like Cliff Click, John Rose,
Doug Lea, have proposed solutions that range from pure obscure technical to pure
educational ones, demonstrating possible \emph{megamorphic inlining friendly}
coding styles.

Scala, as most of the modern JVM languages, is no exception and it suffers from
The Problem too and, actually, it affects its adoption negatively. At the end of
2011, an email from a Yammer employee towards the CEO of TypeSafe, the company
backing the Scala ecosystem, about Scala shortcomings, leaked to the public
\fxfatal{cite http://www.infoq.com/news/2011/11/yammer-scala}. Most complaints were
related with The Problem and, more specifically, with the Scala standard
library collections' performance. 

In the next chapters we will see where exactly the problem lies and how
our project can help us alleviate it. We have named our project
\textsc{ft-declosurify}; the ft prefix stands for Scala compiler's FastTrack
mechanism, as we will see in Chapter X, and the declosurify suffix suggests that
the implementation is based on Paul Phillips's original \textsc{declosurify} project
fxfatal{cite github url}. 

ft-declosurify defines two methods, \texttt{macroMap} and \texttt{macroForeach}, that can be used
from all the Scala standard libary collections. They offer the same
functionality as their Scala standard library counterparts, \texttt{map} and \texttt{foreach}
methods, but they are much faster because they suffer much less from The
Problem. In most cases, \texttt{macroMap}/\texttt{macroForeach} can be considered as faster and
drop-in replacements of the default \texttt{map}/\texttt{foreach} methods.

Our solution tries to attack The Problem using Scala's new compile-time
reflection subsystem. The next chapter will give us an overview of both the
Scala collections and the new compile-time reflection capabilities.
